{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f752a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport src.dataset_utils\n",
    "%aimport src.display_utils\n",
    "%aimport src.batch_utils\n",
    "%aimport src.classifier_basic\n",
    "%aimport src.classifier_ml\n",
    "\n",
    "import src.dataset_utils as dataset_utils\n",
    "import src.batch_utils as batch_utils\n",
    "import src.classifier_basic as classifier_basic\n",
    "import src.classifier_ml as classifier_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a4fa3",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "[High-Resolution Fundus (HRF) Image Database](https://www5.cs.fau.de/research/data/fundus-images/) - maintained by FAU Erlangen-Nürnberg\n",
    "\n",
    "The HRF dataset contains 45 entries of high-resolution fundus images. When arranged lexicographically, the first 5 entries are used for showcase purposes, while the remaining 40 entries are used for training and testing purposes.\n",
    "\n",
    "**Note:** Due to licensing issues, none of the visualizations are displayed in this repository. To visualize the results, please run the code locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e3ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'hrf'\n",
    "\n",
    "dataset_utils.prepare_dataset(dataset_dir)\n",
    "dataset_manager = dataset_utils.DatasetManager(dataset_dir)\n",
    "\n",
    "entry_ids_showcase = list(range(0, 5))\n",
    "entry_ids_train_test = list(range(5, dataset_manager.dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4de011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_dr\n",
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.73 |\n",
      "| specificity        : 0.97 |\n",
      "| g-mean(sens, spec) : 0.84 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "01_g\n",
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.71 |\n",
      "| specificity        : 0.98 |\n",
      "| g-mean(sens, spec) : 0.84 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "01_h\n",
      "| accuracy           : 0.95 |\n",
      "| sensitivity        : 0.62 |\n",
      "| specificity        : 0.99 |\n",
      "| g-mean(sens, spec) : 0.78 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "02_dr\n",
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.68 |\n",
      "| specificity        : 0.98 |\n",
      "| g-mean(sens, spec) : 0.82 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "02_g\n",
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.70 |\n",
      "| specificity        : 0.98 |\n",
      "| g-mean(sens, spec) : 0.83 |\n",
      "\\___________________________/\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_basic.evaluate_collection(dataset_manager, entry_ids_showcase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06972a8d",
   "metadata": {},
   "source": [
    "## Batch processing\n",
    "\n",
    "The images from the HRF dataset are processed in full resolution, which is 3504x2336 pixels.\n",
    "\n",
    "Due to RAM constraints, processing these images in full resolution is not feasible on most machines, so the images are divided into smaller batches. Batches are saved locally and then processed one by one.\n",
    "\n",
    "Current setup requires 32 GB of RAM and 80 GB of disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6d767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batching train_test: 100%|██████████| 40/40 [00:37<00:00,  1.07entry/s]\n",
      "Batching showcase: 100%|██████████| 5/5 [02:25<00:00, 29.06s/entry]\n"
     ]
    }
   ],
   "source": [
    "batch_manager = batch_utils.BatchManager('batches')\n",
    "\n",
    "batch_info = batch_utils.BatchInfo(patch_side=21,\n",
    "                                   patch_step_train_test=5,\n",
    "                                   patch_step_showcase=1,\n",
    "                                   entry_ids_train_test=entry_ids_train_test,\n",
    "                                   entry_ids_showcase=entry_ids_showcase,\n",
    "                                   bpi_test=2,\n",
    "                                   bpi_showcase=4,\n",
    "                                   train_size=0.7,\n",
    "                                   under_sampling_strat=0.3)\n",
    "\n",
    "batch_utils.batch(dataset_manager, batch_manager, batch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7403569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 40/40 [03:57<00:00,  5.94s/entry]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.82 |\n",
      "| specificity        : 0.97 |\n",
      "| g-mean(sens, spec) : 0.89 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "01_dr\n",
      "| accuracy           : 0.95 |\n",
      "| sensitivity        : 0.81 |\n",
      "| specificity        : 0.96 |\n",
      "| g-mean(sens, spec) : 0.88 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "01_g\n",
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.80 |\n",
      "| specificity        : 0.97 |\n",
      "| g-mean(sens, spec) : 0.88 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "01_h\n",
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.81 |\n",
      "| specificity        : 0.98 |\n",
      "| g-mean(sens, spec) : 0.89 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "02_dr\n",
      "| accuracy           : 0.94 |\n",
      "| sensitivity        : 0.83 |\n",
      "| specificity        : 0.95 |\n",
      "| g-mean(sens, spec) : 0.89 |\n",
      "\\___________________________/\n",
      "\n",
      "\n",
      "02_g\n",
      "| accuracy           : 0.96 |\n",
      "| sensitivity        : 0.82 |\n",
      "| specificity        : 0.97 |\n",
      "| g-mean(sens, spec) : 0.89 |\n",
      "\\___________________________/\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = classifier_ml.create_model(max_iter=500,\n",
    "                                   learning_rate=0.1,\n",
    "                                   min_samples_leaf=40,\n",
    "                                   max_leaf_nodes=121,\n",
    "                                   max_depth=None,\n",
    "                                   l2_regularization=0.2,\n",
    "                                   scoring='loss')\n",
    "\n",
    "classifier_ml.train_and_test(batch_manager, batch_info, model)\n",
    "classifier_ml.evaluate_collection(dataset_manager, batch_manager, batch_info, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
